{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import os   \n",
    "import cv2 as cv           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed: The specified procedure could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5af05cc94ba6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified procedure could not be found."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2                     \n",
    "import os      \n",
    "import tensorflow            \n",
    "from random import shuffle\n",
    "from tqdm import tqdm  \n",
    "import random\n",
    "#for opening and loading image\n",
    "from PIL import Image\n",
    "#for preprocessing\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "#Doing One hot encoding as classifier has multiple classes\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout  \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from random import shuffle\n",
    "#For augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#MobileNetV2 model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras import Model, layers\n",
    "from numpy import loadtxt\n",
    "\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "#from tensorflow.keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting path of directory\n",
    "B_DIR = \"/content/drive/My Drive/skin_cancer_dataset/Basal_cell_carcinoma/train/\"\n",
    "M_DIR =  \"/content/drive/My Drive/skin_cancer_dataset/Melanoma/train/\"\n",
    "N_DIR = \"/content/drive/My Drive/skin_cancer_dataset/Nevus/train/\"\n",
    "\n",
    "\n",
    "# storing all the files from directories PARA_DIR and NORM_DIR to Pimages and Nimages for accessing images directly\n",
    "Bimages = os.listdir(B_DIR)\n",
    "Mimages = os.listdir(M_DIR)\n",
    "Nimages = os.listdir(N_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_parasite = random.sample(Bimages,6)\n",
    "f,ax = plt.subplots(2,3,figsize=(15,9))\n",
    "\n",
    "for i in range(0,6):\n",
    "    im = cv2.imread(\"/content/drive/My Drive/skin_cancer_dataset/Basal_cell_carcinoma/train/\" +sample_parasite[i])\n",
    "    ax[i//3,i%3].imshow(im)\n",
    "    ax[i//3,i%3].axis('off')\n",
    "f.suptitle('Basal Cell Carcinoma sample images',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_parasite = random.sample(Mimages,6)\n",
    "f,ax = plt.subplots(2,3,figsize=(15,9))\n",
    "\n",
    "for i in range(0,6):\n",
    "    im = cv2.imread(M_DIR +sample_parasite[i])\n",
    "    ax[i//3,i%3].imshow(im)\n",
    "    ax[i//3,i%3].axis('off')\n",
    "f.suptitle('Melanoma sample images',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_parasite = random.sample(Nimages,6)\n",
    "f,ax = plt.subplots(2,3,figsize=(15,9))\n",
    "\n",
    "for i in range(0,6):\n",
    "    im = cv2.imread(N_DIR +sample_parasite[i])\n",
    "    ax[i//3,i%3].imshow(im)\n",
    "    ax[i//3,i%3].axis('off')\n",
    "f.suptitle('Nevus sample images',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "Basal=os.listdir(\"/content/drive/My Drive/skin_cancer_dataset/Basal_cell_carcinoma/train/\")\n",
    "for a in Basal:\n",
    "    try:\n",
    "        image=cv2.imread(\"/content/drive/My Drive/skin_cancer_dataset/Basal_cell_carcinoma/train/\"+a)\n",
    "        image_from_array = Image.fromarray(image, 'RGB')\n",
    "        size_image = image_from_array.resize((224, 224))\n",
    "        data.append(np.array(size_image))\n",
    "        labels.append(0)\n",
    "    except AttributeError:\n",
    "        print(\"\")\n",
    "\n",
    "Melanoma=os.listdir(\"/content/drive/My Drive/skin_cancer_dataset/Melanoma/train/\")\n",
    "for b in Melanoma:\n",
    "    try:\n",
    "        image=cv2.imread(\"/content/drive/My Drive/skin_cancer_dataset/Melanoma/train/\"+b)\n",
    "        image_from_array = Image.fromarray(image, 'RGB')\n",
    "        size_image = image_from_array.resize((224, 224))\n",
    "        data.append(np.array(size_image))\n",
    "        labels.append(1)\n",
    "    except AttributeError:\n",
    "        print(\"\")\n",
    "Nevus=os.listdir(\"/content/drive/My Drive/skin_cancer_dataset/Nevus/train/\")\n",
    "for c in Nevus:\n",
    "    try:\n",
    "        image=cv2.imread(\"/content/drive/My Drive/skin_cancer_dataset/Nevus/train/\"+c)\n",
    "        image_from_array = Image.fromarray(image, 'RGB')\n",
    "        size_image = image_from_array.resize((224, 224))\n",
    "        data.append(np.array(size_image))\n",
    "        labels.append(2)\n",
    "    except AttributeError:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting features and labels in array\n",
    "feats=np.array(data)\n",
    "labels=np.array(labels)\n",
    "\n",
    "# saving features and labels for later re-use\n",
    "np.save(\"/content/drive/My Drive/skin_cancer_dataset/feats_train\",feats)\n",
    "np.save(\"/content/drive/My Drive/skin_cancer_dataset/labels_train\",labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats=np.load(\"/content/drive/My Drive/skin_cancer_dataset/feats_train.npy\")\n",
    "labels=np.load(\"/content/drive/My Drive/skin_cancer_dataset/labels_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.arange(feats.shape[0])\n",
    "np.random.shuffle(s)\n",
    "feats=feats[s]\n",
    "labels=labels[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=len(np.unique(labels))\n",
    "len_data=len(feats)\n",
    "print(len_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting cells images into 80:20 ratio i.e., 80% for training and 20% for testing purpose\n",
    "(x_train,x_test)=feats[(int)(0.2*len_data):],feats[:(int)(0.2*len_data)]\n",
    "\n",
    "(y_train,y_test)=labels[(int)(0.2*len_data):],labels[:(int)(0.2*len_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')/255 # As we are working on image data we are normalizing data by dividing 255.\n",
    "x_test = x_test.astype('float32')/255\n",
    "train_len=len(x_train)\n",
    "test_len=len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=to_categorical(y_train,3)\n",
    "y_test=to_categorical(y_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAug  = ImageDataGenerator(\n",
    "featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = MobileNetV2(\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3),\n",
    "    weights='imagenet')\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = conv_base.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation='relu')(x) \n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "predictions = layers.Dense(3, activation='softmax')(x)\n",
    "model = Model(conv_base.input, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint('.mdl_wts.hdf5', monitor='val_loss',mode='min',verbose=1, save_best_only=True),\n",
    "             ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=1, mode='min', min_lr=0.00000000001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "BS = 64\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "\ttrainAug.flow(x_train,y_train, batch_size=BS),\n",
    "\tsteps_per_epoch=train_len // BS,\n",
    "\tvalidation_data=(x_test, y_test),\n",
    "\tvalidation_steps=test_len // BS,\n",
    "\tepochs=30,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('.mdl_wts.hdf5')\n",
    "model.save('/content/drive/My Drive/skin_model/model_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('/content/drive/My Drive/skin_model/model_v1.h5')\n",
    "# checking the accuracy \n",
    "accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('\\n', 'Test_Accuracy:-', accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = model.predict(x_test, batch_size=16, verbose=0)\n",
    "rounded_predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(rounded_predictions,axis=1)\n",
    "rounded_labels=np.argmax(y_test, axis=1)\n",
    "\n",
    "pred_Y = model.predict(x_test, batch_size = 16, verbose = True)\n",
    "BS=16\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    target_names =['BCC','Melanoma','Nevus']\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(x_test, batch_size=BS)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(pred_Y,axis=1) \n",
    "# Convert validation observations to one hot vectors\n",
    "# compute the confusion matrix\n",
    "rounded_labels=np.argmax(y_test, axis=1)\n",
    "confusion_mtx = confusion_matrix(rounded_labels, Y_pred_classes)\n",
    "\n",
    " \n",
    "\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predIdxs = model.predict(x_test, batch_size=BS)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "rounded_labels=np.argmax(y_test, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(rounded_labels, predIdxs,target_names=['BCC','Melanoma','Nevus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "n_classes = 3\n",
    "\n",
    "pred_Y = model.predict(x_test, batch_size = 16, verbose = True)\n",
    "# Plot linewidth.\n",
    "lw = 2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], pred_Y[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), pred_Y.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "Basal=os.listdir(\"/content/drive/My Drive/skin_cancer_dataset/Basal_cell_carcinoma/test/\")\n",
    "for a in Basal:\n",
    "    try:\n",
    "        image=cv2.imread(\"/content/drive/My Drive/skin_cancer_dataset/Basal_cell_carcinoma/test/\"+a)\n",
    "        image_from_array = Image.fromarray(image, 'RGB')\n",
    "        size_image = image_from_array.resize((224, 224))\n",
    "        data.append(np.array(size_image))\n",
    "        labels.append(0)\n",
    "    except AttributeError:\n",
    "        print(\"\")\n",
    "\n",
    "Melanoma=os.listdir(\"/content/drive/My Drive/skin_cancer_dataset/Melanoma/test/\")\n",
    "for b in Melanoma:\n",
    "    try:\n",
    "        image=cv2.imread(\"/content/drive/My Drive/skin_cancer_dataset/Melanoma/test/\"+b)\n",
    "        image_from_array = Image.fromarray(image, 'RGB')\n",
    "        size_image = image_from_array.resize((224, 224))\n",
    "        data.append(np.array(size_image))\n",
    "        labels.append(1)\n",
    "    except AttributeError:\n",
    "        print(\"\")\n",
    "Nevus=os.listdir(\"/content/drive/My Drive/skin_cancer_dataset/Nevus/test/\")\n",
    "for c in Nevus:\n",
    "    try:\n",
    "        image=cv2.imread(\"/content/drive/My Drive/skin_cancer_dataset/Nevus/test/\"+c)\n",
    "        image_from_array = Image.fromarray(image, 'RGB')\n",
    "        size_image = image_from_array.resize((224, 224))\n",
    "        data.append(np.array(size_image))\n",
    "        labels.append(2)\n",
    "    except AttributeError:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_test=np.array(data)\n",
    "labels_test=np.array(labels)\n",
    "\n",
    "np.save(\"/content/drive/My Drive/skin_cancer_dataset/feats_test\",feats_test)\n",
    "np.save(\"/content/drive/My Drive/skin_cancer_dataset/labels_test\",labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_test=np.load(\"/content/drive/My Drive/skin_cancer_dataset/feats_test.npy\")\n",
    "labels_test=np.load(\"/content/drive/My Drive/skin_cancer_dataset/labels_test.npy\")\n",
    "\n",
    "num_classes=len(np.unique(labels_test))\n",
    "len_data=len(feats_test)\n",
    "print(len_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = feats_test.astype('float32')/255\n",
    "y_valid=to_categorical(labels_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = model.predict(x_valid, batch_size = 10, verbose = True)\n",
    "rounded_predictions = model.predict(x_valid, batch_size=16, verbose=0)\n",
    "pred = np.argmax(rounded_predictions,axis=1)\n",
    "rounded_labels=np.argmax(y_valid, axis=1)\n",
    "BS=10\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    target_names =['BCC','Melanoma','Nevus']\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(x_valid, batch_size=BS)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(pred_Y,axis=1) \n",
    "# Convert validation observations to one hot vectors\n",
    "# compute the confusion matrix\n",
    "rounded_labels=np.argmax(y_valid, axis=1)\n",
    "confusion_mtx = confusion_matrix(rounded_labels, Y_pred_classes)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = \"/content/drive/MyDrive/skin_cancer_dataset/Nevus/test/nv_ISIC_0000211.jpg\"\n",
    "img2 =\"/content/drive/MyDrive/skin_cancer_dataset/Melanoma/test/melanoma_ISIC_0000159.jpg\"\n",
    "img3 = \"/content/drive/MyDrive/skin_cancer_dataset/Basal_cell_carcinoma/test/bcc_ISIC_0057937.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict ={\"Basal_Cell_Carcinoma\":0,\n",
    "             \"Melanoma\":1,\n",
    "             \"Nevus\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import  display\n",
    "def pred_image(img_path,model):\n",
    "  img = Image.open(img_path).resize((224,224)) #target_size must agree with what the trained model expects!!\n",
    "  # Preprocessing the image\n",
    "  img = image.img_to_array(img)\n",
    "  img = np.expand_dims(img, axis=0)\n",
    "  img = img.astype('float32')/255\n",
    "  \n",
    "  preds = model.predict(img)\n",
    "  pred = np.argmax(preds,axis = 1)\n",
    "  pred_cat = [k for k, v in class_dict.items() if v == pred[0]][0]\n",
    "  \n",
    "  return pred_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_image(img1,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_image(img2,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_image(img3,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf-keras-vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "img_path='/content/drive/MyDrive/skin_cancer_dataset/Melanoma/test/melanoma_ISIC_0000159.jpg'\n",
    "img = Image.open(img_path).resize((224,224)) #target_size must agree with what the trained model expects!!\n",
    "\n",
    "# Preprocessing the image\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = img.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image of size 299x299\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
    "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 299, 299, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image\n",
    "img_size=(224,224)\n",
    "#img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
    "img_path='/content/drive/MyDrive/skin_cancer_dataset/Melanoma/test/melanoma_ISIC_0000159.jpg'\n",
    "img = Image.open(img_path).resize((224,224)) #target_size must agree with what the trained model expects!!\n",
    "\n",
    "# Preprocessing the image\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = img.astype('float32')/255\n",
    "\n",
    "# Remove last layer's softmax\n",
    "model.layers[-1].activation = None\n",
    "\n",
    "# Print what the top predicted class is\n",
    "preds = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate class activation heatmap\n",
    "last_conv_layer_name = \"block_16_depthwise\"\n",
    "heatmap = make_gradcam_heatmap(img, model, last_conv_layer_name)\n",
    "\n",
    "# Display heatmap\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from tensorflow.keras.preprocessing import image as im\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import tensorflow as tf\n",
    "img_path='/content/drive/MyDrive/skin_cancer_dataset/Melanoma/test/melanoma_ISIC_0000159.jpg'\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"/content/drive/MyDrive/skin_cancer_dataset/cam.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    # img = im.open(img_path).resize((224,224)) #target_size must agree with what the trained model expects!!\n",
    "\n",
    "    # # Preprocessing the image\n",
    "    # img = im.img_to_array(img)\n",
    "    # img = np.expand_dims(img, axis=0)\n",
    "    # img = img.astype('float32')/255\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(cam_path))\n",
    "\n",
    "\n",
    "save_and_display_gradcam(img_path, heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names=[layer.name for layer in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f5583cf1d9466b5c27e75c89cc6b383bed5736d6b16c51c8074d8690011a952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
